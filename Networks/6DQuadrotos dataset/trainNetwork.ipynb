{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "torch.set_printoptions(precision=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x = scipy.io.loadmat(\"X_train_nnmpc.mat\")\n",
    "y = scipy.io.loadmat(\"y_train_nnmpc.mat\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'__header__': b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Sun May 31 22:20:51 2020',\n '__version__': '1.0',\n '__globals__': [],\n 'y_train_nnmpc': array([[-0.01432,  0.08944, 13.69237],\n        [ 0.05785,  0.06024, 12.81854],\n        [ 0.01456, -0.34623, 11.96521],\n        ...,\n        [-0.34395,  0.29669,  7.03248],\n        [-0.15769,  0.29727,  7.6887 ],\n        [-0.19847, -0.36397,  8.80287]])}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"quadRotorTrainDataReachSdp.mat\",{\"Xtrain\": x['X_train_nnmpc'], \"Ytrain\":y['y_train_nnmpc']})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainCompleteLoop = False\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "# fileName = \"fourDimTrainData.mat\"\n",
    "fileName = \"quadRotorTrainDataReachSdp.mat\"\n",
    "# data = loadmat(fileName)\n",
    "# XFull = data['X']\n",
    "# YFull = data['y']\n",
    "data = loadmat(fileName)\n",
    "XFull = data['Xtrain']\n",
    "YFull = data['Ytrain']\n",
    "# A = data['A']\n",
    "# B = data['B']\n",
    "if XFull.shape[0] < XFull.shape[1]:\n",
    "    XFull = XFull.T\n",
    "    YFull = YFull.T\n",
    "if \"quad\" in fileName:\n",
    "    A = np.zeros((6, 6), dtype=np.float32)\n",
    "    A[0, 3] = 1.\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3), dtype=np.float32)\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1), dtype=np.float32)\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "    lastDim = 3\n",
    "elif \"doubleIntegrator\" in fileName:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "    lastDim = 1\n",
    "elif \"fourDim\" in fileName:\n",
    "    pass\n",
    "    lastDim = 2\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "if trainCompleteLoop:\n",
    "    YFull = (A @ XFull.T + B @ YFull.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "dataSplit = 0.9\n",
    "trainSize = int(dataSplit * XFull.shape[0])\n",
    "\n",
    "\n",
    "# net = nn.Sequential(\n",
    "#     nn.Linear(4, 16),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(16, 16),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(16, 16),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(16, lastDim),)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, lastDim))\n",
    "numberOfLayers = (len(net) + 1) // 2\n",
    "net.to(device)\n",
    "train_batch_size = 64\n",
    "\n",
    "def my_loss(output, target):\n",
    "    prod = torch.linalg.norm(net[0].weight)\n",
    "    for i in range(1, numberOfLayers):\n",
    "        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "    loss = torch.mean((output - target)**2) + gamma * prod\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(3279, 3)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YFull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "checkpointResume = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 gamma 0 lambda: 4.0\n",
      "validation losses average:  tensor(0.00370449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 0 gamma 0.0 lambda: 3.98799991607666\n",
      "MSE loss:  0.0045494195073843 , Norm of product: tensor(349.74884033, device='cuda:0')\n",
      "epoch: 10 gamma 0.0 lambda: 3.881606340408325\n",
      "validation losses average:  tensor(0.00359313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 10 gamma 0.0 lambda: 3.8699615001678467\n",
      "MSE loss:  0.002211988437920809 , Norm of product: tensor(347.54269409, device='cuda:0')\n",
      "epoch: 20 gamma 0.0 lambda: 3.766716718673706\n",
      "validation losses average:  tensor(0.00327992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 20 gamma 0.0 lambda: 3.7554163932800293\n",
      "MSE loss:  0.0019483842188492417 , Norm of product: tensor(345.52117920, device='cuda:0')\n",
      "epoch: 30 gamma 0.0 lambda: 3.6552278995513916\n",
      "validation losses average:  tensor(0.00254348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 30 gamma 0.0 lambda: 3.6442620754241943\n",
      "MSE loss:  0.0038354801945388317 , Norm of product: tensor(343.73596191, device='cuda:0')\n",
      "epoch: 40 gamma 0.0 lambda: 3.5470387935638428\n",
      "validation losses average:  tensor(0.00245203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 40 gamma 0.0 lambda: 3.536397695541382\n",
      "MSE loss:  0.0020659049041569233 , Norm of product: tensor(342.24832153, device='cuda:0')\n",
      "epoch: 50 gamma 0.0 lambda: 3.4420523643493652\n",
      "validation losses average:  tensor(0.00170766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 50 gamma 0.0 lambda: 3.4317262172698975\n",
      "MSE loss:  0.0009939941810443997 , Norm of product: tensor(341.37655640, device='cuda:0')\n",
      "epoch: 60 gamma 0.0 lambda: 3.34017276763916\n",
      "validation losses average:  tensor(0.00131762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 60 gamma 0.0 lambda: 3.3301522731781006\n",
      "MSE loss:  0.0008606007322669029 , Norm of product: tensor(339.63635254, device='cuda:0')\n",
      "epoch: 70 gamma 0.0 lambda: 3.2413089275360107\n",
      "validation losses average:  tensor(0.00110802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 70 gamma 0.0 lambda: 3.2315850257873535\n",
      "MSE loss:  0.0007657118840143085 , Norm of product: tensor(337.07852173, device='cuda:0')\n",
      "epoch: 80 gamma 0.0 lambda: 3.145371437072754\n",
      "validation losses average:  tensor(0.00113184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 80 gamma 0.0 lambda: 3.1359353065490723\n",
      "MSE loss:  0.0019653167109936476 , Norm of product: tensor(334.96554565, device='cuda:0')\n",
      "epoch: 90 gamma 0.0 lambda: 3.052273750305176\n",
      "validation losses average:  tensor(0.00089399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 90 gamma 0.0 lambda: 3.043116807937622\n",
      "MSE loss:  0.00040492202970199287 , Norm of product: tensor(332.61135864, device='cuda:0')\n",
      "epoch: 100 gamma 0.0 lambda: 2.961930990219116\n",
      "validation losses average:  tensor(0.00110526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 100 gamma 0.0 lambda: 2.953045129776001\n",
      "MSE loss:  0.0008203021716326475 , Norm of product: tensor(330.40362549, device='cuda:0')\n",
      "epoch: 110 gamma 0.0 lambda: 2.8742623329162598\n",
      "validation losses average:  tensor(0.00089548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 110 gamma 0.0 lambda: 2.8656394481658936\n",
      "MSE loss:  0.0008833465399220586 , Norm of product: tensor(328.76293945, device='cuda:0')\n",
      "epoch: 120 gamma 0.0 lambda: 2.7891886234283447\n",
      "validation losses average:  tensor(0.00127225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 120 gamma 0.0 lambda: 2.7808210849761963\n",
      "MSE loss:  0.000511341670062393 , Norm of product: tensor(327.24740601, device='cuda:0')\n",
      "epoch: 130 gamma 0.0 lambda: 2.7066333293914795\n",
      "validation losses average:  tensor(0.00086002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 130 gamma 0.0 lambda: 2.6985132694244385\n",
      "MSE loss:  0.0007766518974676728 , Norm of product: tensor(325.87017822, device='cuda:0')\n",
      "epoch: 140 gamma 0.0 lambda: 2.626520872116089\n",
      "validation losses average:  tensor(0.00065783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 140 gamma 0.0 lambda: 2.6186411380767822\n",
      "MSE loss:  0.0005218196311034262 , Norm of product: tensor(324.77905273, device='cuda:0')\n",
      "epoch: 150 gamma 0.0 lambda: 2.5487794876098633\n",
      "validation losses average:  tensor(0.00065672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 150 gamma 0.0 lambda: 2.541133165359497\n",
      "MSE loss:  0.0007010959088802338 , Norm of product: tensor(323.76095581, device='cuda:0')\n",
      "epoch: 160 gamma 0.0 lambda: 2.473339557647705\n",
      "validation losses average:  tensor(0.00055239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 160 gamma 0.0 lambda: 2.4659194946289062\n",
      "MSE loss:  0.00030859053367748857 , Norm of product: tensor(322.77896118, device='cuda:0')\n",
      "epoch: 170 gamma 0.0 lambda: 2.400132417678833\n",
      "validation losses average:  tensor(0.00049964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 170 gamma 0.0 lambda: 2.3929319381713867\n",
      "MSE loss:  0.0004966601263731718 , Norm of product: tensor(321.94265747, device='cuda:0')\n",
      "epoch: 180 gamma 0.0 lambda: 2.329092264175415\n",
      "validation losses average:  tensor(0.00047364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 180 gamma 0.0 lambda: 2.3221049308776855\n",
      "MSE loss:  0.0002253684651805088 , Norm of product: tensor(321.01586914, device='cuda:0')\n",
      "epoch: 190 gamma 0.0 lambda: 2.260154962539673\n",
      "validation losses average:  tensor(0.00058941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 190 gamma 0.0 lambda: 2.2533743381500244\n",
      "MSE loss:  0.0009332996560260653 , Norm of product: tensor(320.32376099, device='cuda:0')\n",
      "epoch: 200 gamma 0.0 lambda: 2.193258047103882\n",
      "validation losses average:  tensor(0.00043502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 200 gamma 0.0 lambda: 2.186678171157837\n",
      "MSE loss:  0.00032261715386994183 , Norm of product: tensor(319.69415283, device='cuda:0')\n",
      "epoch: 210 gamma 0.0 lambda: 2.1283411979675293\n",
      "validation losses average:  tensor(0.00046113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 210 gamma 0.0 lambda: 2.1219561100006104\n",
      "MSE loss:  0.0004515480250120163 , Norm of product: tensor(319.14065552, device='cuda:0')\n",
      "epoch: 220 gamma 0.0 lambda: 2.065345525741577\n",
      "validation losses average:  tensor(0.00044793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 220 gamma 0.0 lambda: 2.0591495037078857\n",
      "MSE loss:  0.0003636526525951922 , Norm of product: tensor(318.70239258, device='cuda:0')\n",
      "epoch: 230 gamma 0.0 lambda: 2.0042145252227783\n",
      "validation losses average:  tensor(0.00048773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 230 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.00026585947489365935 , Norm of product: tensor(318.25061035, device='cuda:0')\n",
      "epoch: 240 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00041965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 240 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.000176529967575334 , Norm of product: tensor(317.75466919, device='cuda:0')\n",
      "epoch: 250 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00042096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 250 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.0005510640330612659 , Norm of product: tensor(317.47543335, device='cuda:0')\n",
      "epoch: 260 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00039195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 260 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.00018632327555678785 , Norm of product: tensor(317.08792114, device='cuda:0')\n",
      "epoch: 270 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00040850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 270 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.0004342849424574524 , Norm of product: tensor(316.76113892, device='cuda:0')\n",
      "epoch: 280 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00037478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 280 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.00026836738106794655 , Norm of product: tensor(316.57586670, device='cuda:0')\n",
      "epoch: 290 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.00037047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 290 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  0.00034332252107560635 , Norm of product: tensor(316.29522705, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gammaScheduler = 1.01\n",
    "gammaStopThreshold = 1e-5\n",
    "lambdaVal = torch.Tensor([4.]).to(device)\n",
    "minimumLambda = 2\n",
    "lambdaScheduler = 0.997\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if checkpointResume:\n",
    "    checkpointDictionary = torch.load(\"checkpoint.pth\")\n",
    "    optimizer.load_state_dict(checkpointDictionary[\"optimizerStateDict\"])\n",
    "    scheduler.load_state_dict(checkpointDictionary[\"schedulerState\"])\n",
    "    net.load_state_dict(checkpointDictionary[\"networkStateDict\"])\n",
    "    bestStateDict = checkpointDictionary[\"bestStateDict\"]\n",
    "    bestLoss = checkpointDictionary[\"bestLoss\"]\n",
    "    trainLosses = checkpointDictionary['trainLosses']\n",
    "    validationLosses = checkpointDictionary['validationLosses']\n",
    "    gamma = checkpointDictionary['gamma']\n",
    "    trainset = checkpointDictionary['trainSet']\n",
    "    testSet = checkpointDictionary['testSet']\n",
    "\n",
    "\n",
    "    # epoch = checkpointDictionary['maxEpoch']\n",
    "    startingEpoch = checkpointDictionary['epoch']\n",
    "    epoch = 1000\n",
    "else:\n",
    "\n",
    "    trainset, testSet = torch.utils.data.random_split(torch.utils.data.TensorDataset(torch.Tensor(XFull), torch.Tensor(YFull)), [trainSize, XFull.shape[0] - trainSize])\n",
    "    startingEpoch = 0\n",
    "    epoch = 300\n",
    "    trainLosses = []\n",
    "    validationLosses = []\n",
    "    # gamma = 1e-7\n",
    "    gamma = 0\n",
    "    bestStateDict = None\n",
    "    bestLoss = 100000\n",
    "    criterion = my_loss\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=train_batch_size, num_workers=2)\n",
    "loaders = {\"train\": trainloader, \"eval\": testLoader}\n",
    "\n",
    "\n",
    "for t in range(startingEpoch, epoch):\n",
    "    for phase in {\"train\", 'eval'}:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        tempValidationLosses = []\n",
    "        for i, (X, Y) in enumerate(loaders[phase]):\n",
    "\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            out = net(X)\n",
    "            loss = criterion(out, Y)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    # for j in range(numberOfLayers):\n",
    "                    #     net[2 * j].weight /= torch.maximum(torch.tensor([1.]).to(device), (torch.linalg.norm(net[2 * j].weight) / lambdaVal))\n",
    "            else:\n",
    "                tempValidationLosses.append(loss)\n",
    "                if loss < bestLoss:\n",
    "                    bestLoss = loss\n",
    "                    bestStateDict = net.state_dict()\n",
    "                    torch.save(bestStateDict, \"tempBestStateDict.pth\")\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "            # if gamma > gammaStopThreshold:\n",
    "            if gamma < gammaStopThreshold:\n",
    "                gamma *= gammaScheduler\n",
    "            if lambdaVal > minimumLambda:\n",
    "                lambdaVal *= lambdaScheduler\n",
    "            trainLosses.append(loss.item())\n",
    "            checkpointDictionary = \\\n",
    "                {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "                \"schedulerState\": scheduler.state_dict(),\n",
    "                 \"networkStateDict\": net.state_dict(),\n",
    "                 \"bestStateDict\": bestStateDict,\n",
    "                 \"bestLoss\": bestLoss,\n",
    "                 \"trainLosses\": trainLosses,\n",
    "                 \"validationLosses\": validationLosses,\n",
    "                 \"epoch\": t,\n",
    "                 \"maxEpoch\": epoch,\n",
    "                 \"gamma\": gamma,\n",
    "                 \"trainSet\": trainset,\n",
    "                 \"testSet\": testSet}\n",
    "            torch.save(checkpointDictionary, \"checkpoint.pth\")\n",
    "        else:\n",
    "            validationLosses.append(sum(tempValidationLosses[:-1]) / (len(tempValidationLosses) - 1))\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"epoch:\", t, \"gamma\", gamma, \"lambda:\", lambdaVal.item())\n",
    "            if phase == \"train\":\n",
    "                with torch.no_grad():\n",
    "                    prod = torch.linalg.norm(net[0].weight)\n",
    "                    for i in range(1, numberOfLayers):\n",
    "                        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "                    print('MSE loss: ', loss.item(), \", Norm of product:\", prod)\n",
    "            else:\n",
    "                print(\"validation losses average: \", validationLosses[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "checkpointDictionary = \\\n",
    "    {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "    \"schedulerState\": scheduler.state_dict(),\n",
    "     \"networkStateDict\": net.state_dict(),\n",
    "     \"bestStateDict\": bestStateDict,\n",
    "     \"bestLoss\": bestLoss,\n",
    "     \"trainLosses\": trainLosses,\n",
    "     \"validationLosses\": validationLosses,\n",
    "     \"epoch\": t,\n",
    "     \"maxEpoch\": epoch,\n",
    "     \"gamma\": gamma,\n",
    "     \"trainSet\": trainset,\n",
    "     \"testSet\": testSet}\n",
    "torch.save(checkpointDictionary, \"checkpoint.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.692507930625227, 4.802495848532838, 4.69725583944506, 4.702747801646405)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 6\n",
    "device = torch.device(\"cpu\")\n",
    "net.to(device)\n",
    "lowerCoordinate = torch.Tensor([4.6975, 4.6975, 2.9975, 0.9499, -0.0001, -0.0001]).to(device)\n",
    "upperCoordinate = torch.Tensor([4.7025, 4.7025 ,3.0025, 0.9501,  0.0001,  0.0001 ]).to(device)\n",
    "inputData = (upperCoordinate - lowerCoordinate) * torch.rand(1000, dim, device=device) \\\n",
    "                                                        + lowerCoordinate\n",
    "plt.scatter(inputData[:, 0], inputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "outputData = net(inputData).detach().cpu().numpy()\n",
    "if lastDim == 3:\n",
    "    outputData = (A @ inputData.detach().cpu().numpy().T + B @ outputData.T + C).T\n",
    "plt.scatter(outputData[:, 0], outputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "plt.axis(\"equal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 6])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "lastDim = 6\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"tempBestStateDict.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainCompleteLoop = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss:  tensor(0.00020069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "# net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    print(\"1\")\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.9.pth\")\n",
    "else:\n",
    "    print(\"2\")\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV3.0.pth\")\n",
    "    # torch.save(networkClass.state_dict(), \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(net)):\n",
    "    if i % 2 == 0:\n",
    "        weights.append(net[i].weight.clone().detach().cpu().numpy())\n",
    "        biases.append(net[i].bias.clone().detach().cpu().unsqueeze(1).numpy())\n",
    "torch.save({\"biases\": biases, \"weights\": weights, \"AMatrix\": A, \"BMatrix\": B}, \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.1.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11457, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}